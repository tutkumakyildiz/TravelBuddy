# Quantization Requirements
torch>=2.0.0
transformers>=4.35.0
optimum>=1.15.0
onnx>=1.15.0
onnxruntime>=1.16.0
tensorflow>=2.13.0
bitsandbytes>=0.41.0
accelerate>=0.20.0
sentencepiece>=0.1.99
protobuf>=3.20.0

# Optional for specific quantization methods
# intel-extension-for-pytorch  # For Intel optimizations
# onnxruntime-gpu             # For GPU inference 